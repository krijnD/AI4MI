{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pyvista as pv\n",
    "import os\n",
    "\n",
    "custom_palette = {\n",
    "    'roze': '#eb8fd8',\n",
    "    'groen': '#b9d4b4',\n",
    "    'paars': '#ba94e9',\n",
    "    'blue': '#4C8BE2',\n",
    "    'orange': '#E27A3F',\n",
    "    'grey_light': '#1F3240',\n",
    "    'grey_dark': '#16242F'\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-23T13:29:33.590385Z",
     "start_time": "2024-10-23T13:29:31.752384Z"
    }
   },
   "id": "98e68a2217ed8458",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d43c86fdb923c018"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-23T13:29:33.622390Z",
     "start_time": "2024-10-23T13:29:33.593384Z"
    }
   },
   "outputs": [],
   "source": [
    "def render_3d_segmentation(pred_volume, gt_volume, volume_id, output_dir):\n",
    "    # pred_volume: Tensor of shape (K, D, H, W)\n",
    "    # gt_volume: Tensor of shape (K, D, H, W)\n",
    "\n",
    "    # Convert to numpy arrays and get label volumes\n",
    "    pred_volume_np = torch.argmax(pred_volume, dim=0).cpu().numpy()  # Shape: (D, H, W)\n",
    "    gt_volume_np = torch.argmax(gt_volume, dim=0).cpu().numpy()\n",
    "\n",
    "    # Transpose the volumes to match PyVista's (X, Y, Z) format\n",
    "    pred_volume_np = np.transpose(pred_volume_np, (2, 1, 0))  # Now shape is (W, H, D)\n",
    "    gt_volume_np = np.transpose(gt_volume_np, (2, 1, 0))\n",
    "\n",
    "    # Create the grids\n",
    "    grid_pred = pv.UniformGrid()\n",
    "    grid_pred.dimensions = pred_volume_np.shape\n",
    "    grid_pred.spacing = (1, 1, 1)\n",
    "    grid_pred.origin = (0, 0, 0)\n",
    "\n",
    "    grid_gt = pv.UniformGrid()\n",
    "    grid_gt.dimensions = gt_volume_np.shape\n",
    "    grid_gt.spacing = (1, 1, 1)\n",
    "    grid_gt.origin = (0, 0, 0)\n",
    "\n",
    "    # Assign the label data to 'point_data'\n",
    "    grid_pred.point_data[\"labels\"] = pred_volume_np.flatten(order=\"F\")\n",
    "    grid_gt.point_data[\"labels\"] = gt_volume_np.flatten(order=\"F\")\n",
    "\n",
    "    # Define class names and colors (adjust as needed)\n",
    "    class_names = ['Background', 'Esophagus', 'Heart', 'Trachea', 'Aorta']\n",
    "    class_colors = [\n",
    "        'gray',  # Background\n",
    "        custom_palette['roze'],  # Esophagus\n",
    "        custom_palette['groen'],  # Heart\n",
    "        custom_palette['paars'],  # Trachea\n",
    "        custom_palette['blue']  # Aorta\n",
    "    ]\n",
    "\n",
    "    # Create the plotter\n",
    "    p = pv.Plotter(shape=(1, 2), window_size=(1600, 800), off_screen=True)\n",
    "\n",
    "    # Function to add class surfaces\n",
    "    def add_class_surfaces(grid, subplot_index, title):\n",
    "        p.subplot(0, subplot_index)\n",
    "        for c in range(1, len(class_names)):  # Skip background if desired\n",
    "            class_label = c\n",
    "            # Threshold the grid to extract the class\n",
    "            class_grid = grid.threshold(value=(class_label - 0.1, class_label + 0.1), scalars='labels')\n",
    "            if class_grid.n_points == 0:\n",
    "                continue  # Skip if no points for this class\n",
    "            # Extract the surface mesh\n",
    "            surface = class_grid.contour(isosurfaces=[class_label], scalars='labels')\n",
    "            # Add the mesh to the plotter\n",
    "            p.add_mesh(surface, color=class_colors[c], opacity=0.6, label=class_names[c])\n",
    "        p.add_legend(bcolor='white')\n",
    "        p.add_axes()\n",
    "        p.set_background('white')\n",
    "        p.add_title(title)\n",
    "\n",
    "    # Add ground truth surfaces\n",
    "    add_class_surfaces(grid_gt, subplot_index=0, title='Ground Truth')\n",
    "\n",
    "    # Add prediction surfaces\n",
    "    add_class_surfaces(grid_pred, subplot_index=1, title='Prediction')\n",
    "\n",
    "    # Link the views\n",
    "    p.link_views()\n",
    "\n",
    "    # Define the camera positions you want to capture\n",
    "    camera_positions = {\n",
    "        'isometric': 'iso',\n",
    "        'front': 'xz',\n",
    "        'side': 'yz',\n",
    "        'top': 'xy',\n",
    "    }\n",
    "\n",
    "    # Save a screenshot for each camera position\n",
    "    for view_name, camera_pos in camera_positions.items():\n",
    "        # Set the camera position\n",
    "        p.camera_position = camera_pos\n",
    "        # Update rendering\n",
    "        p.render()\n",
    "        # Save the rendering to a file\n",
    "        screenshot_path = os.path.join(output_dir, f'Patient_{volume_id}_{view_name}_view.png')\n",
    "        p.screenshot(screenshot_path)\n",
    "        print(f\"Saved {view_name} view to {screenshot_path}\")\n",
    "\n",
    "    # Close the plotter\n",
    "    p.close()\n",
    "    print(f\"Rendered 3D segmentation saved to {screenshot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import torch\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "def load_nifti_as_tensor(nifti_path, num_classes):\n",
    "    \"\"\"\n",
    "    Loads a NIfTI file and converts it into a one-hot encoded PyTorch tensor.\n",
    "    Resamples the data to have isotropic voxel sizes to correct aspect ratio distortion.\n",
    "\n",
    "    Args:\n",
    "        nifti_path (str): Path to the NIfTI file (.nii or .nii.gz).\n",
    "        num_classes (int): Total number of classes (including background).\n",
    "\n",
    "    Returns:\n",
    "        tensor_volume (torch.Tensor): One-hot encoded tensor of shape (K, D, H, W).\n",
    "    \"\"\"\n",
    "    # Load the NIfTI file\n",
    "    nifti_img = nib.load(nifti_path)\n",
    "    volume_data = nifti_img.get_fdata()\n",
    "\n",
    "    # Print some information\n",
    "    print(f\"Loaded NIfTI file from {nifti_path}\")\n",
    "    print(f\"Original volume shape: {volume_data.shape}\")\n",
    "    print(f\"Data type: {volume_data.dtype}\")\n",
    "\n",
    "    # Reorient the image to RAS+ (standard orientation)\n",
    "    canonical_img = nib.as_closest_canonical(nifti_img)\n",
    "    volume_data = canonical_img.get_fdata()\n",
    "\n",
    "    # Get voxel sizes from the canonical image\n",
    "    voxel_sizes = canonical_img.header.get_zooms()\n",
    "    print(f\"Voxel sizes (after reorientation): {voxel_sizes}\")\n",
    "\n",
    "    # Get axes codes after reorientation\n",
    "    aff = canonical_img.affine\n",
    "    axes_codes = nib.orientations.aff2axcodes(aff)\n",
    "    print(f\"Axes codes after reorientation: {axes_codes}\")\n",
    "\n",
    "    # Transpose the data to match the expected (D, H, W) shape\n",
    "    # After reorientation, the data is in (Z, Y, X) order\n",
    "    volume_data = np.transpose(volume_data, (2, 1, 0))  # Now shape is (D, H, W)\n",
    "    print(f\"Volume shape after transpose: {volume_data.shape}\")\n",
    "\n",
    "    # Resample the data to isotropic voxel sizes\n",
    "    # Determine the scaling factors to achieve isotropic voxel sizes\n",
    "    # We'll use the smallest voxel size among x, y, and z as the target voxel size\n",
    "    target_voxel_size = min(voxel_sizes)\n",
    "    scaling_factors = (\n",
    "        voxel_sizes[2] / target_voxel_size,  # scaling factor for D (Z-axis)\n",
    "        voxel_sizes[1] / target_voxel_size,  # scaling factor for H (Y-axis)\n",
    "        voxel_sizes[0] / target_voxel_size   # scaling factor for W (X-axis)\n",
    "    )\n",
    "    print(f\"Scaling factors: {scaling_factors}\")\n",
    "\n",
    "    # Since we're dealing with labels, use nearest-neighbor interpolation\n",
    "    # to resample the data without introducing new labels\n",
    "    volume_data_resampled = zoom(volume_data, zoom=scaling_factors, order=0)\n",
    "    print(f\"Volume shape after resampling: {volume_data_resampled.shape}\")\n",
    "\n",
    "    # Convert volume data to integer type (assuming labels are integers)\n",
    "    volume_data_resampled = volume_data_resampled.astype(np.int32)\n",
    "\n",
    "    # Determine the unique labels in the resampled volume\n",
    "    unique_labels = np.unique(volume_data_resampled)\n",
    "    print(f\"Unique labels in the resampled volume: {unique_labels}\")\n",
    "\n",
    "    # Create one-hot encoded tensor\n",
    "    K = num_classes\n",
    "    D, H, W = volume_data_resampled.shape\n",
    "    tensor_volume = torch.zeros((K, D, H, W), dtype=torch.float32)\n",
    "\n",
    "    # Fill the tensor with one-hot encoding\n",
    "    for k in range(num_classes):\n",
    "        tensor_volume[k] = torch.from_numpy((volume_data_resampled == k).astype(np.float32))\n",
    "\n",
    "    return tensor_volume\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-23T13:29:37.343384Z",
     "start_time": "2024-10-23T13:29:33.624390Z"
    }
   },
   "id": "368f74aaa7e17016",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cell that runs the code"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2855344baa99169d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded NIfTI file from ../../data/segthor_original/train/Patient_01/GT.nii.gz\n",
      "Original volume shape: (512, 512, 229)\n",
      "Data type: float64\n",
      "Voxel sizes (after reorientation): (0.9765625, 0.9765625, 2.0)\n",
      "Axes codes after reorientation: ('R', 'A', 'S')\n",
      "Volume shape after transpose: (229, 512, 512)\n",
      "Scaling factors: (2.048, 1.0, 1.0)\n",
      "Volume shape after resampling: (469, 512, 512)\n",
      "Unique labels in the resampled volume: [0 1 2 3 4]\n",
      "Loaded NIfTI file from ../../data/segthor_original/train/Patient_02/GT.nii.gz\n",
      "Original volume shape: (512, 512, 246)\n",
      "Data type: float64\n",
      "Voxel sizes (after reorientation): (0.976562, 0.976562, 2.5)\n",
      "Axes codes after reorientation: ('R', 'A', 'S')\n",
      "Volume shape after transpose: (246, 512, 512)\n",
      "Scaling factors: (2.5600011, 1.0, 1.0)\n",
      "Volume shape after resampling: (630, 512, 512)\n",
      "Unique labels in the resampled volume: [0 1 2 3 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivvbr\\anaconda3\\envs\\ai4mi\\lib\\site-packages\\pyvista\\core\\grid.py:912: PyVistaDeprecationWarning: `UniformGrid` is deprecated. Use `ImageData` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "gt_nifti_path = '../../data/segthor_original/train/Patient_01/GT.nii.gz'\n",
    "pred_nifti_path = '../../data/segthor_original/train/Patient_02/GT.nii.gz'\n",
    "num_classes = 5  # Adjust based on your dataset (including background)\n",
    "\n",
    "# Load and process the ground truth volume\n",
    "gt_volume = load_nifti_as_tensor(gt_nifti_path, num_classes)\n",
    "\n",
    "# Load and process the prediction volume\n",
    "pred_volume = load_nifti_as_tensor(pred_nifti_path, num_classes)\n",
    "\n",
    "# Now you can use gt_volume and pred_volume in your plotting functions\n",
    "volume_id = 'volume_identifier'  # Adjust as needed\n",
    "output_dir = '.'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "render_3d_segmentation(pred_volume, gt_volume, volume_id, output_dir='.')\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-10-23T13:29:37.346386Z"
    }
   },
   "id": "a68e914498421bc6",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Some deprecated stuff"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "88af8daa8851a35f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# THIS IS ONLY USED FOR PICKLE OBJECTS OF THE PREDICTIONS IN VOLUME\n",
    "\n",
    "# def animate_3d_volume(volume_predictions, volume_ground_truths, evaluate_dir):\n",
    "#     # Assuming volume_predictions and volume_ground_truths are defined as before\n",
    "#     ids = [1, 13, 22, 28, 30]\n",
    "#     for volume_id in ids:\n",
    "#         # Retrieve the list of slices for the given volume_id\n",
    "#         pred_slices = volume_predictions[volume_id]  # List of (slice_idx, pred_slice)\n",
    "#         gt_slices = volume_ground_truths[volume_id]  # List of (slice_idx, gt_slice)\n",
    "# \n",
    "#         # Sort the slices by slice_idx\n",
    "#         pred_slices_sorted = sorted(pred_slices, key=lambda x: x[0])\n",
    "#         gt_slices_sorted = sorted(gt_slices, key=lambda x: x[0])\n",
    "# \n",
    "#         # Stack the slices into a Tensor volume\n",
    "#         pred_volume = torch.stack([slice_data for idx, slice_data in pred_slices_sorted], dim=1)\n",
    "#         gt_volume = torch.stack([slice_data for idx, slice_data in gt_slices_sorted], dim=1)\n",
    "# \n",
    "#         # Now pred_volume and gt_volume are Tensors of shape (K, D, H, W)\n",
    "#         # where K is the number of classes, D is the depth (number of slices)\n",
    "# \n",
    "#         # Call the rendering function\n",
    "#         # render_3d_segmentation(pred_volume, gt_volume, volume_id)\n",
    "#         render_3d_segmentation(pred_volume, gt_volume, volume_id, output_dir=evaluate_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c1cb8b2287c40020"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d2b80d698740cc62"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# ANIMATION CODE\n",
    "\n",
    "# import torch\n",
    "# import pyvista as pv\n",
    "# import numpy as np\n",
    "# import os\n",
    "# \n",
    "# def render_3d_segmentation_with_animation(pred_volume, gt_volume, volume_id, output_dir):\n",
    "#     # pred_volume and gt_volume: Tensors of shape (K, D, H, W)\n",
    "# \n",
    "#     # Convert to numpy arrays and get label volumes\n",
    "#     pred_volume_np = torch.argmax(pred_volume, dim=0).cpu().numpy()  # Shape: (D, H, W)\n",
    "#     gt_volume_np = torch.argmax(gt_volume, dim=0).cpu().numpy()\n",
    "# \n",
    "#     # Transpose the volumes to match PyVista's (X, Y, Z) format\n",
    "#     pred_volume_np = np.transpose(pred_volume_np, (2, 1, 0))  # Now shape is (W, H, D)\n",
    "#     gt_volume_np = np.transpose(gt_volume_np, (2, 1, 0))\n",
    "# \n",
    "#     # Create the grids\n",
    "#     grid_pred = pv.UniformGrid()\n",
    "#     grid_pred.dimensions = pred_volume_np.shape\n",
    "#     grid_pred.spacing = (1, 1, 1)\n",
    "#     grid_pred.origin = (0, 0, 0)\n",
    "#     grid_pred.point_data[\"labels\"] = pred_volume_np.flatten(order=\"F\")\n",
    "# \n",
    "#     grid_gt = pv.UniformGrid()\n",
    "#     grid_gt.dimensions = gt_volume_np.shape\n",
    "#     grid_gt.spacing = (1, 1, 1)\n",
    "#     grid_gt.origin = (0, 0, 0)\n",
    "#     grid_gt.point_data[\"labels\"] = gt_volume_np.flatten(order=\"F\")\n",
    "# \n",
    "#     # Define class names and colors (adjust as needed)\n",
    "#     class_names = ['Background', 'Esophagus', 'Heart', 'Trachea', 'Aorta']\n",
    "#     class_colors = ['gray', 'red', 'green', 'blue', 'yellow']\n",
    "# \n",
    "#     # Create the plotter with subplots\n",
    "#     p = pv.Plotter(shape=(1, 2), off_screen=True, window_size=(1600, 800))\n",
    "# \n",
    "#     # Function to add class surfaces to a subplot\n",
    "#     def add_class_surfaces(grid, subplot_index, title):\n",
    "#         p.subplot(0, subplot_index)\n",
    "#         for c in range(1, len(class_names)):  # Skip background if desired\n",
    "#             class_label = c\n",
    "#             # Threshold the grid to extract the class\n",
    "#             class_grid = grid.threshold(value=(class_label - 0.1, class_label + 0.1), scalars='labels')\n",
    "#             if class_grid.n_points == 0:\n",
    "#                 continue  # Skip if no points for this class\n",
    "#             # Extract the surface mesh\n",
    "#             surface = class_grid.contour(isosurfaces=[class_label], scalars='labels')\n",
    "#             # Add the mesh to the plotter\n",
    "#             p.add_mesh(surface, color=class_colors[c], opacity=0.6, label=class_names[c])\n",
    "#         p.add_legend(bcolor='white')\n",
    "#         p.add_axes()\n",
    "#         p.set_background('white')\n",
    "#         p.add_title(title)\n",
    "# \n",
    "#     # Add ground truth to the first subplot\n",
    "#     add_class_surfaces(grid_gt, subplot_index=0, title='Ground Truth')\n",
    "# \n",
    "#     # Add prediction to the second subplot\n",
    "#     add_class_surfaces(grid_pred, subplot_index=1, title='Prediction')\n",
    "# \n",
    "#     # Link the views so that camera movements affect both subplots\n",
    "#     p.link_views()\n",
    "# \n",
    "#     # Set the camera position\n",
    "#     p.camera_position = 'iso'  # Isometric view\n",
    "# \n",
    "#     # Prepare to capture frames\n",
    "#     num_frames = 60\n",
    "#     rotation_angle = 360 / num_frames\n",
    "# \n",
    "#     # Directory to save frames\n",
    "#     frames_dir = os.path.join(output_dir, f'volume_{volume_id}_frames')\n",
    "#     os.makedirs(frames_dir, exist_ok=True)\n",
    "# \n",
    "#     # Capture frames\n",
    "#     for i in range(num_frames):\n",
    "#         # Rotate the camera\n",
    "#         p.camera.Azimuth(rotation_angle)\n",
    "#         # Update rendering\n",
    "#         p.render()\n",
    "#         # Save frame\n",
    "#         frame_path = os.path.join(frames_dir, f'frame_{i:03d}.png')\n",
    "#         p.screenshot(frame_path)\n",
    "# \n",
    "#     # Close the plotter\n",
    "#     p.close()\n",
    "# \n",
    "#     # Create an animation (e.g., GIF)\n",
    "#     animation_path = os.path.join(output_dir, f'volume_{volume_id}_animation.gif')\n",
    "#     import imageio\n",
    "#     with imageio.get_writer(animation_path, mode='I', duration=0.05) as writer:\n",
    "#         for i in range(num_frames):\n",
    "#             frame_path = os.path.join(frames_dir, f'frame_{i:03d}.png')\n",
    "#             image = imageio.imread(frame_path)\n",
    "#             writer.append_data(image)\n",
    "# \n",
    "#     print(f\"Animation saved to {animation_path}\")\n",
    "# \n",
    "#     # Optionally, remove the frames directory to save space\n",
    "#     import shutil\n",
    "#     shutil.rmtree(frames_dir)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "300e96663d4dee02",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "db6adad2b8aa3fc5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
